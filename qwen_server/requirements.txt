# QWEN Server Dependencies

# Core ML/Vision
torch>=2.0.0
torchvision>=0.15.0
transformers>=4.51.0  # Required for Qwen3-VL support (Qwen3VLForConditionalGeneration)
accelerate>=0.25.0
Pillow>=10.0.0

# Quantization support (INT8/INT4)
# bitsandbytes enables LLM.int8() and NF4/FP4 quantization
# Requires CUDA and compute capability >= 7.0 (Volta or newer)
bitsandbytes>=0.41.0

# Model specific
qwen-vl-utils>=0.0.1  # Qwen VL utilities
einops>=0.7.0

# Web Framework
fastapi>=0.104.0
uvicorn[standard]>=0.24.0
pydantic>=2.0.0
python-multipart>=0.0.6

# Utilities
pyyaml>=6.0
numpy>=1.24.0
python-dotenv>=1.0.0
